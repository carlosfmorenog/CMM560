{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 5 Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity you will use a database of **\"extracted features\"** to perform different types of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `scikit-learn`, `scipy`, `plotly_express` and `matplotlib` for this activity. If you don't have these packages already, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install scipy\n",
    "!pip install plotly_express\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `IRIS` database, which contains 150 samples of the sepal and petal lengths and widths from 3 different iris flower species: Setosa, Versicolor and Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Fig 1: Iris dataset.](https://www.dropbox.com/s/kqgsr9tmjdgou4g/iris.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is already available in Python by importing the `sklearn.datasets` function and using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load iris dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that we will **NOT** work with the actual images, but rather with the numerical information extracted from some real flower samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, this dataset was presented in 1936 by a statistician called Ronald Fisher, and thus we don't even have access to the original images to extract some proper feature from!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The dataset is contained on a **dictionary-like** structure referred to as **sklearn.utils.Bunch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you print this dataset, you will see a lot of things contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Therefore, we need to extract each index of this dictionary into a different variables to understand and analyse them separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, we will import the `features` into a variable called `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = iris['data']\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data is stored in a `numpy array` of 150 rows and 4 columns, each corresponding to the  measurements of a flower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, we will import the `headers` of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "header = iris['feature_names']\n",
    "print(header, type(header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Why do you think the features and the header are stored separately?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Afterwards, we will import the **class/target**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target = iris['target']\n",
    "print(target, type(target), target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The class/target is a `numpy array` which contains the **category** of each flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each sample is labelled as $0$, $1$ or $2$ instead of the iris type since the labels can be better used as numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A separate key called **target_names** contains the name corresponding to each numerical label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target_names = iris['target_names']\n",
    "print(target_names, type(target_names), target_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Why do you think the target and the target names are stored separately?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, We can use `list comprehension` to obtain a list of names instead of numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"target_named\" and store the actual categories\n",
    "target_named = [target_names[t] for t in target]\n",
    "print(target_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, just in case you are interested, there is an entry called `DESC` containing the description of the dataset (a string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "iris['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can create a [Pandas](https://pandas.pydata.org/) dataframe with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data = data, columns = header)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can plot using a package called [Plotly Express](https://plotly.com/python/plotly-express/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "# Since we cannot plot 4 axis, we will use one of the features as size\n",
    "px.scatter_3d(df, x=\"petal length (cm)\", y=\"petal width (cm)\", z=\"sepal length (cm)\", \n",
    "              size=\"sepal width (cm)\", color=target_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the features of the Setosas are notably distinct to the other two types. Therefore, we would expect that a machine learning algorithm is at least capable of identifying all Setosas correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classifiaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is split the dataset in to `training` and `testing` data. For this activity, you are required to reserve **80% of the data for training** and **20% of the data for testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either create your own code to do this division or use a function available elsewhere, just **make sure that samples of the three classes of iris flowers are present on both training and testing data!**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following cell to split your dataset into training and testing\n",
    "## Hint: Explore the train_test_split() function in sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you modify your code to ensure that in both datasets there is a balanced number of samples (i.e. 40/40/40 on `training` and 10/10/10 on `testing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following cell to split your dataset into training and testing guaranteeing balance\n",
    "## Hint: Investigate about stratification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a Suport Vector Machine (SVM) classifier using the training data and testing it in the test data. To do so, you need to import `SCV` from the `sklearn.svm` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train a SVM model with a linear kernel (more information about what this means can be found [here](https://towardsdatascience.com/support-vector-machine-python-example-d67d9b63f1c8)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to **fit** our model and store the result in a variable called `clf`. **FOR VISUALISATION PURPOSES, WE WILL ONLY TRAIN USING THE FIRST TWO FEATURES OF THE DATASET**, which are `sepal length` and `sepal width`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainng the classifier only using the first two columns of the training data\n",
    "clf = model.fit(X_train[:,0:2],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise how our model will be capable to classify test samples into the different categories, let's plot the **decision boundary surface of our model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we need to define two functions: \n",
    "* `make_meshgrid`: This function will create a mesh object for the minimum and maximum objects.\n",
    "* `plot_contours`: This function will learn how to extract the contours of `clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a plot with the mesh grid and the contours using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "title = ('Decision surface of linear SVC')\n",
    "# To create the mesh grid we use the first and second column\n",
    "xx, yy = make_meshgrid(X_train[:, 0],X_train[:, 1])\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X_train[:, 0],X_train[:, 1], c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "\n",
    "ax.set_xlabel('Sepal Length')\n",
    "ax.set_ylabel('Sepal Width')\n",
    "\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our model on the `test` data, we will **predict** it. **Keep in mind that since we trained with only two features, we should also test with the same two features as well**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test[:,0:2])\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare the **model's accuracy** of the obtained labels in `y_predicted` against the ground truth in `y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print model's accuracy\n",
    "comparison = y_predicted == y_test\n",
    "print('Accuracy', sum(comparison)/len(comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you print the accuracy for each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this cell to print the accuracy for each class\n",
    "## Hint: Use the numpy.where() function to find where does a vector have a certain value i.e. 0/1/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out how different kernel types affect the performance of the SVM classifier [here](https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html). Would you consider using a different kernel for this classifier?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
