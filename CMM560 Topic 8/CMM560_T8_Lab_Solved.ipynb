{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 8 Laboratory (Solved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, you will use imbalanced datasets from the [Keel](https://sci2s.ugr.es/keel/imbalanced.php) public repository to appropriately evaluate performance metric in two popular classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation in Binary Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and making sense of the necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [glass](https://sci2s.ugr.es/keel/dataset/data/imbalanced/glass-names.txt) dataset. This one has 214 samples of 7 different types of glasses. Each glass sample has 9 features, each corresponding to a different element that composes a glass sample: Rl(??), Na, Mg, Al, Si, K, Ca, Ba and Fe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will start with binary datasets, we will first use the [glass0](https://sci2s.ugr.es/keel/keel-dataset/datasets/imbalanced/imb_IRlowerThan9/names/glass0-names.txt) version of the dataset. The only difference of this one with respect of the original one is that a certain glass class called `class 0` is compared against the rest of the glass classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click [here](https://sci2s.ugr.es/keel/dataset.php?cod=141) to visit the *glass0* description website, go to the bottom (where it says **Files and additional references** and download the **complete data set**. Unzip the file and store it **in the same directory as this jupyter notebook**. You should get a file with the extension *.dat*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import the data from the file into Python, to do so, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.51588824 12.87795     3.43036    ...  8.04468     0.\n",
      "   0.1224    ]\n",
      " [ 1.5176423  12.9777      3.53812    ...  8.52888     0.\n",
      "   0.        ]\n",
      " [ 1.52212996 14.20795     3.82099    ...  9.5726      0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.51837126 14.321       3.25974    ...  5.78508     1.62855\n",
      "   0.        ]\n",
      " [ 1.51657164 14.7998      0.         ...  8.2814      1.71045\n",
      "   0.        ]\n",
      " [ 1.51732338 14.95275     0.         ...  8.61496     1.5498\n",
      "   0.        ]] (214, 9)\n",
      "[' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' positive' ' positive'\n",
      " ' positive' ' positive' ' positive' ' positive' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative' ' negative' ' negative'\n",
      " ' negative' ' negative' ' negative' ' negative'] (214,)\n"
     ]
    }
   ],
   "source": [
    "#Notice that in my case, I stored glass0.dat inside a folder called data...\n",
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('data/glass0.dat',\n",
    "                     usecols=range(9), # this only brings the first nine columns of the dataset\n",
    "                     skip_header=14, # The first 14 lines of the .dat contain a description\n",
    "                     delimiter=',')\n",
    "\n",
    "\n",
    "target_names = np.genfromtxt('data/glass0.dat',\n",
    "                     usecols=range(9,10), # This brings the last column of the dataset, which has the class\n",
    "                     dtype = None,\n",
    "                     encoding = None, # This helps us get the strings in a numpy array\n",
    "                     skip_header=14,\n",
    "                     delimiter=',')\n",
    "\n",
    "print(data,data.shape)\n",
    "print(target_names,target_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that once again, we will store the data and the target in separate variables. Moreover, we will generate a new target variable called `target` with `positive=0` and `negative=1` using the **list comprehension** technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (214,)\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "target = [0 if i == ' positive' else 1 for i in target_names]\n",
    "target=np.array(target)\n",
    "print(target,target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we chose 0 to be the positive and 1 to be the negatve since the [glass0 documentation](https://sci2s.ugr.es/keel/dataset.php?cod=141) said so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to train a supervised learning model to evaluate. In this case we will use two popular classification models so that we can compare which is better for this dataset: **Support Vector Machine (SVM)** vs. **Random Forests (RF)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split our dataset into training and testing sets (80% train, 20% test). You have already done this in the past!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative samples in the training set:  56 115\n",
      "Number of positive and negative samples in the test set:  14 29\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to split your dataset into training and testing w/ stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,stratify=target,test_size=0.2)\n",
    "print('Number of positive and negative samples in the training set: ',np.count_nonzero(y_train == 0),np.count_nonzero(y_train == 1))\n",
    "print('Number of positive and negative samples in the test set: ',np.count_nonzero(y_test == 0),np.count_nonzero(y_test == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a SVM model called `model_svm` using the training data and predict the test data. Store the fitted model in a variable called `clf_svm` and the prediction results in a variable called `y_svm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 1 1] (43,)\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to train a SVM model to predict the labels of the test data\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(kernel='linear')\n",
    "clf_svm = model_svm.fit(X_train,y_train)\n",
    "y_svm = model_svm.predict(X_test)\n",
    "print(y_svm,y_svm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, train a RF model called `model_rf` (using the `RandomForestClassifier()` function contained in `sklearn.ensemble` package) on the same training data and predict the test data. Store the results in variables called `clf_rf` and `y_rf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1\n",
      " 1 1 0 1 1 1] (43,)\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to train a RF model to predict the labels of the test data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "clf_rf = model_rf.fit(X_train, y_train)\n",
    "y_rf = model_rf.predict(X_test)\n",
    "print(y_rf,y_rf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `y_svm` and `y_rf` should be *numpy* array vectors of size (43,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In week 3 lab, we saw that once that we predict the values for the test set, we can compare both the `y_test` vector with the predicted vectors (in our case `y_svm` and `y_rf`) to obtain the results. If you recall, it was quite tricky to do this as we had more classes in the vector! Therefore, this time we will do it slightly different..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should know that everything in Python can be imported! Performance metrics can be imported as well. We will first use accuracy (although it should be very clear by now that this one is not suitable for imbalanced datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM:  0.7674418604651163\n",
      "Accuracy of RF:  0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of SVM: ', accuracy_score(y_svm, y_test))\n",
    "print('Accuracy of RF: ', accuracy_score(y_rf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which is the best classifier in terms of accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** RF, since [some sources](https://elitedatascience.com/imbalanced-classes) suggest that decision-tree based models learn better from imbalance data compared to vector-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's lecture we saw that one of the most robust metrics for accuracy in the *imbalanced* world is the area under the receiver operating characteristic curve (or AUC-ROC for short). To get this metric, we need to retrain our models, this time in a probabilistic way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that by setting the input `probability=True` when generating our SVM model (RF doesn't need it) and by changing `predict` to `predict_proba`, we will not obtain a fixed output, but instead a probability (value between 0 and 1) of the classification to be 0 or 1 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the previous models/classes/predictions in our workspace, train new (probabilistic) models in the following cell and store the trained models as `model_svm_proba` and `model_rf_proba`, the classifiers as `clf_svm_proba` and `clf_rf_proba`, and the outputs as `y_svm_proba` and `y_rf_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.81342463e-01 6.18657537e-01]\n",
      " [5.95938244e-02 9.40406176e-01]\n",
      " [4.49598053e-01 5.50401947e-01]\n",
      " [3.06180762e-01 6.93819238e-01]\n",
      " [2.83012157e-01 7.16987843e-01]\n",
      " [4.13955683e-01 5.86044317e-01]\n",
      " [2.82204205e-01 7.17795795e-01]\n",
      " [6.80471132e-01 3.19528868e-01]\n",
      " [2.29000664e-01 7.70999336e-01]\n",
      " [5.83015088e-01 4.16984912e-01]\n",
      " [5.46887346e-01 4.53112654e-01]\n",
      " [3.12021594e-01 6.87978406e-01]\n",
      " [6.95383150e-01 3.04616850e-01]\n",
      " [1.07712392e-06 9.99998923e-01]\n",
      " [4.66094179e-01 5.33905821e-01]\n",
      " [2.17012224e-02 9.78298778e-01]\n",
      " [2.35506105e-02 9.76449389e-01]\n",
      " [1.69825888e-01 8.30174112e-01]\n",
      " [2.50943367e-01 7.49056633e-01]\n",
      " [3.61024416e-01 6.38975584e-01]\n",
      " [1.75481972e-05 9.99982452e-01]\n",
      " [7.16248064e-02 9.28375194e-01]\n",
      " [5.19211470e-03 9.94807885e-01]\n",
      " [3.14031133e-01 6.85968867e-01]\n",
      " [4.13312250e-01 5.86687750e-01]\n",
      " [5.44429887e-01 4.55570113e-01]\n",
      " [7.53399697e-06 9.99992466e-01]\n",
      " [4.19990730e-01 5.80009270e-01]\n",
      " [4.44761067e-01 5.55238933e-01]\n",
      " [7.45356095e-06 9.99992546e-01]\n",
      " [2.18473341e-01 7.81526659e-01]\n",
      " [3.40928278e-02 9.65907172e-01]\n",
      " [2.63213334e-01 7.36786666e-01]\n",
      " [4.40879146e-01 5.59120854e-01]\n",
      " [3.51677377e-01 6.48322623e-01]\n",
      " [6.97293457e-01 3.02706543e-01]\n",
      " [5.68681484e-02 9.43131852e-01]\n",
      " [3.35148952e-01 6.64851048e-01]\n",
      " [1.46816471e-02 9.85318353e-01]\n",
      " [5.55812777e-01 4.44187223e-01]\n",
      " [5.30662093e-01 4.69337907e-01]\n",
      " [4.59736753e-07 9.99999540e-01]\n",
      " [2.66923581e-01 7.33076419e-01]] (43, 2)\n",
      "[[0.198 0.802]\n",
      " [0.048 0.952]\n",
      " [0.108 0.892]\n",
      " [0.031 0.969]\n",
      " [0.019 0.981]\n",
      " [0.147 0.853]\n",
      " [0.015 0.985]\n",
      " [0.816 0.184]\n",
      " [0.223 0.777]\n",
      " [0.512 0.488]\n",
      " [0.877 0.123]\n",
      " [0.564 0.436]\n",
      " [0.826 0.174]\n",
      " [0.008 0.992]\n",
      " [0.259 0.741]\n",
      " [0.05  0.95 ]\n",
      " [0.067 0.933]\n",
      " [0.039 0.961]\n",
      " [0.4   0.6  ]\n",
      " [0.59  0.41 ]\n",
      " [0.034 0.966]\n",
      " [0.014 0.986]\n",
      " [0.005 0.995]\n",
      " [0.587 0.413]\n",
      " [0.736 0.264]\n",
      " [0.698 0.302]\n",
      " [0.023 0.977]\n",
      " [0.568 0.432]\n",
      " [0.486 0.514]\n",
      " [0.041 0.959]\n",
      " [0.088 0.912]\n",
      " [0.039 0.961]\n",
      " [0.454 0.546]\n",
      " [0.522 0.478]\n",
      " [0.3   0.7  ]\n",
      " [0.746 0.254]\n",
      " [0.017 0.983]\n",
      " [0.021 0.979]\n",
      " [0.024 0.976]\n",
      " [0.789 0.211]\n",
      " [0.269 0.731]\n",
      " [0.065 0.935]\n",
      " [0.052 0.948]] (43, 2)\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to re-train the models in a probabilistic way\n",
    "model_svm_proba = SVC(kernel='linear', probability=True)\n",
    "clf_svm_proba = model_svm_proba.fit(X_train,y_train)\n",
    "y_svm_proba = clf_svm_proba.predict_proba(X_test)\n",
    "\n",
    "model_rf_proba = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "clf_rf_proba = model_rf_proba.fit(X_train, y_train)\n",
    "y_rf_proba = clf_rf_proba.predict_proba(X_test)\n",
    "\n",
    "print(y_svm_proba,y_svm_proba.shape)\n",
    "print(y_rf_proba,y_rf_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `y_svm_proba` and `y_rf_proba` you should get *numpy* arrays of shape (43, 2), as now each output contains the probability of each sample to be 0 (first value) or 1 (second value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate the AUC-ROC. We will **not** get the plot (as we don't have different thresholds), but rather we will obtain the numeric area under the curve (a value between 0 and 1, the larger the better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain this values, you can run the following cell (provided that you have correctly calculated `y_svm_proba` and `y_rf_proba` in the previous step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for SVM:  0.11822660098522168\n",
      "AUC for RF:  0.07635467980295564\n"
     ]
    }
   ],
   "source": [
    "## Testing AUC-ROC considering the probabilities of the positive class (i.e. 0)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# First, we need to extract only the probabilities of classifying 0 (second column of our numpy arrays)\n",
    "# We can do this once again by means of list comprehension\n",
    "y_svm_proba_0 = [p[0] for p in y_svm_proba]\n",
    "y_rf_proba_0 = [p[0] for p in y_rf_proba]\n",
    "\n",
    "print('AUC for SVM: ',roc_auc_score(y_test, y_svm_proba_0))\n",
    "print('AUC for RF: ',roc_auc_score(y_test, y_rf_proba_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are getting AUC-ROC values **smaller than 0.5** then you can simply invert them (or get the AUC-ROC for the rest/negative class) to get the actual AUC-ROC value for this classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comprehensive explanation of why AUC-ROC cannot be smaller than 0.5 can be found [here](https://www.datascienceblog.net/post/machine-learning/interpreting-roc-curves-auc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for SVM:  0.8817733990147782\n",
      "AUC for RF:  0.9236453201970444\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to test AUC-ROC considering the probabilities of the rest/negative class (i.e. 1)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# First, we need to extract only the probabilities of classifying 1 (second column of our numpy arrays)\n",
    "# We can do this once again by means of list comprehension\n",
    "y_svm_proba_1 = [p[1] for p in y_svm_proba]\n",
    "y_rf_proba_1 = [p[1] for p in y_rf_proba]\n",
    "\n",
    "print('AUC for SVM: ',roc_auc_score(y_test, y_svm_proba_1))\n",
    "print('AUC for RF: ',roc_auc_score(y_test, y_rf_proba_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the classifier that was better in accuracy still better in AUC?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** Depends, but in this case it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the previous results were not product of chance or a lucky data split! To do so, we will use cross validation with $k=5$ folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `KFold()`function contained in the `sklearn.model_selection` package you can split a dataset (in this case, the original one contained in the `data` variable) by using the `get_n_splits()` method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(data)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far you only get a `KFold` object. However, we can put this object inside a for loop to create different training and testing sets in each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "TRAIN INDEXES: [ 43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213]\n",
      "TEST INDEXES: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n",
      "\n",
      "Fold 2:\n",
      "TRAIN INDEXES: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213]\n",
      "TEST INDEXES: [43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66\n",
      " 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n",
      "\n",
      "Fold 3:\n",
      "TRAIN INDEXES: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213]\n",
      "TEST INDEXES: [ 86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
      " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
      " 122 123 124 125 126 127 128]\n",
      "\n",
      "Fold 4:\n",
      "TRAIN INDEXES: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213]\n",
      "TEST INDEXES: [129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168 169 170 171]\n",
      "\n",
      "Fold 5:\n",
      "TRAIN INDEXES: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171]\n",
      "TEST INDEXES: [172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
      " 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\n",
      " 208 209 210 211 212 213]\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print('\\nFold '+str(i)+':')\n",
    "    print('TRAIN INDEXES:', train_index)\n",
    "    print('TEST INDEXES:', test_index)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that what is being printed in the cell above are not the samples, but the indexes from where the samples will be taken in each fold!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the cell below to implement the **stratified** version of KFolds. Remember that stratification will ensure that both classes are equally present in each set for every fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "## Use this cell to do a KFolds split in a stratified way\n",
    "# Hint: Use StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf_strat = StratifiedKFold(n_splits=5)\n",
    "kf_strat.get_n_splits(data, target)\n",
    "print(kf_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate models using cross validation you **don't** need all of this! In fact, you only use this if you want to store your folds or if you want to implement more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a matter of fact it is easier to simply import the `cross_validate` function from the `sklearn.model_selection` package and get the scores as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM cross-validated scores:  {'fit_time': array([0.00199366, 0.00176954, 0.00106311, 0.00099182, 0.0020051 ]), 'score_time': array([0.00099754, 0.        , 0.        , 0.00099921, 0.00199246]), 'test_score': array([0.65116279, 0.72093023, 0.74418605, 0.79069767, 0.76190476])}\n",
      "RF cross-validated scores:  {'fit_time': array([1.93511224, 1.93432689, 2.03058696, 1.79298902, 1.83996248]), 'score_time': array([0.14723229, 0.11646652, 0.12022829, 0.10307693, 0.12174916]), 'test_score': array([0.90697674, 0.88372093, 0.86046512, 0.88372093, 0.85714286])}\n"
     ]
    }
   ],
   "source": [
    "# Cross validatig the original data (the function will do it all)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores_svm = cross_validate(model_svm, data, target, cv=5)\n",
    "print('SVM cross-validated scores: ', scores_svm)\n",
    "scores_rf = cross_validate(model_rf, data, target, cv=5)\n",
    "print('RF cross-validated scores: ', scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From these metrics do you notice any disadvantage of RF?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** RF takes longer to fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, these are not the only metrics you can get from cross validation! Using the `cross_val_scores` function from the `sklearn.model_selection` package you can get (almost) all of the measures that we discussed in class. You can check the [scoring documentation](https://scikit-learn.org/stable/modules/model_evaluation.html) to see what you can calculate,and below you will find some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import cross_val_scores\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM:  [0.65116279 0.72093023 0.74418605 0.79069767 0.76190476]\n",
      "Accuracy for RF:  [0.90697674 0.88372093 0.86046512 0.88372093 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Accuracy for each fold\n",
    "print('Accuracy for SVM: ',cross_val_score(model_svm, data, target, cv=5, scoring = 'accuracy'))\n",
    "print('Accuracy for RF: ',cross_val_score(model_rf, data, target, cv=5, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for SVM:  0.7337763012181617\n",
      "Mean Accuracy for RF:  0.8784053156146179\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(model_svm, data, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(model_rf, data, target, cv=5, scoring = 'accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for SVM:  [0.75       0.84       0.8        0.79411765 0.73684211]\n",
      "Precision for RF:  [0.93103448 0.92857143 0.96       0.9        0.84375   ]\n",
      "Recall for SVM:  [0.72413793 0.72413793 0.82758621 0.93103448 1.        ]\n",
      "Recall for RF:  [0.93103448 0.89655172 0.82758621 0.93103448 0.96428571]\n",
      "F1-Score for SVM:  [0.73684211 0.77777778 0.81355932 0.85714286 0.84848485]\n",
      "F1-Score for RF:  [0.93103448 0.9122807  0.88888889 0.91525424 0.9       ]\n",
      "Mean Precision for SVM:  0.7841919504643962\n",
      "Mean Precision for RF:  0.9126711822660099\n",
      "Mean Recall for SVM:  0.8413793103448276\n",
      "Mean Recall for RF:  0.9100985221674875\n",
      "Mean F1-Score for SVM:  0.8067613821405079\n",
      "Mean F1-Score for RF:  0.9094916621380061\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Precision, Recall and F1-score (both by fold and average)\n",
    "print('Precision for SVM: ',cross_val_score(model_svm, data, target, cv=5, scoring = 'precision'))\n",
    "print('Precision for RF: ',cross_val_score(model_rf, data, target, cv=5, scoring = 'precision'))\n",
    "print('Recall for SVM: ',cross_val_score(model_svm, data, target, cv=5, scoring = 'recall'))\n",
    "print('Recall for RF: ',cross_val_score(model_rf, data, target, cv=5, scoring = 'recall'))\n",
    "print('F1-Score for SVM: ',cross_val_score(model_svm, data, target, cv=5, scoring = 'f1'))\n",
    "print('F1-Score for RF: ',cross_val_score(model_rf, data, target, cv=5, scoring = 'f1'))\n",
    "\n",
    "print('Mean Precision for SVM: ',np.mean(cross_val_score(model_svm, data, target, cv=5, scoring = 'precision')))\n",
    "print('Mean Precision for RF: ',np.mean(cross_val_score(model_rf, data, target, cv=5, scoring = 'precision')))\n",
    "print('Mean Recall for SVM: ',np.mean(cross_val_score(model_svm, data, target, cv=5, scoring = 'recall')))\n",
    "print('Mean Recall for RF: ',np.mean(cross_val_score(model_rf, data, target, cv=5, scoring = 'recall')))\n",
    "print('Mean F1-Score for SVM: ',np.mean(cross_val_score(model_svm, data, target, cv=5, scoring = 'f1')))\n",
    "print('Mean F1-Score for RF: ',np.mean(cross_val_score(model_rf, data, target, cv=5, scoring = 'f1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the Keel repository, there is already a version of the glass dataset called **5FCV**. This means that the authors of this repository already provide a \"proper\" partition of this dataset to test cross validation. If you download this version, you will get 10 *.dat* files instead of 1. **Do you know why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Because there are 5 pairs of files, one for each fold of train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%FOLD 1%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Accuracy of SVM (Fold 1):  0.7209302325581395\n",
      "Accuracy of RF (Fold 1):  0.8837209302325582\n",
      "%%%%%%%%%%%%%FOLD 2%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Accuracy of SVM (Fold 2):  0.7906976744186046\n",
      "Accuracy of RF (Fold 2):  0.8372093023255814\n",
      "%%%%%%%%%%%%%FOLD 3%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Accuracy of SVM (Fold 3):  0.7674418604651163\n",
      "Accuracy of RF (Fold 3):  0.8837209302325582\n",
      "%%%%%%%%%%%%%FOLD 4%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Accuracy of SVM (Fold 4):  0.6511627906976745\n",
      "Accuracy of RF (Fold 4):  0.8372093023255814\n",
      "%%%%%%%%%%%%%FOLD 5%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Accuracy of SVM (Fold 5):  0.8095238095238095\n",
      "Accuracy of RF (Fold 5):  0.9285714285714286\n",
      "%%%%%%%%FINAL RESULTS%%%%%%%%%%%%%\n",
      "Average Accuracy of SVM (All Folds):  0.7479512735326688\n",
      "Average Accuracy of RF (All Folds):  0.8740863787375416\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_final = 0\n",
    "accuracy_rf_final = 0\n",
    "for i in range(5): # Iterate five times\n",
    "    # Load data for each fold\n",
    "    print('%%%%%%%%%%%%%FOLD '+str(i+1)+'%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    X_train = np.genfromtxt('data/glass0-5-'+str(i+1)+'tra.dat',\n",
    "                     usecols=range(9), # this only brings the first nine columns of the dataset\n",
    "                     skip_header=14, # The first 14 lines of the .dat contain a description\n",
    "                     delimiter=',')\n",
    "\n",
    "    y_train_names = np.genfromtxt('data/glass0-5-'+str(i+1)+'tra.dat',\n",
    "                     usecols=range(9,10), # This brings the last column of the dataset, which has the class\n",
    "                     dtype = None,\n",
    "                     encoding = None, # This helps us get the strings in a numpy array\n",
    "                     skip_header=14,\n",
    "                     delimiter=',')\n",
    "    X_test = np.genfromtxt('data/glass0-5-'+str(i+1)+'tst.dat',\n",
    "                     usecols=range(9), # this only brings the first nine columns of the dataset\n",
    "                     skip_header=14, # The first 14 lines of the .dat contain a description\n",
    "                     delimiter=',')\n",
    "    y_test_names = np.genfromtxt('data/glass0-5-'+str(i+1)+'tst.dat',\n",
    "                     usecols=range(9,10), # This brings the last column of the dataset, which has the class\n",
    "                     dtype = None,\n",
    "                     encoding = None, # This helps us get the strings in a numpy array\n",
    "                     skip_header=14,\n",
    "                     delimiter=',')\n",
    "    # Convert target into numbers\n",
    "    y_train = []\n",
    "    y_train = [0 if i == ' positive' else 1 for i in y_train_names]\n",
    "    y_train=np.array(y_train)\n",
    "    y_test = []\n",
    "    y_test = [0 if i == ' positive' else 1 for i in y_test_names]\n",
    "    y_test=np.array(y_test)\n",
    "    # TRAIN-TEST SVM\n",
    "    model_svm = SVC(kernel='linear')\n",
    "    clf_svm = model_svm.fit(X_train,y_train)\n",
    "    y_svm = model_svm.predict(X_test)\n",
    "    # TRAIN-TEST RF\n",
    "    model_rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "    clf_rf = model_rf.fit(X_train, y_train)\n",
    "    y_rf = model_rf.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    print('Accuracy of SVM (Fold '+str(i+1)+'): ', accuracy_score(y_svm, y_test))\n",
    "    print('Accuracy of RF (Fold '+str(i+1)+'): ', accuracy_score(y_rf, y_test))\n",
    "    accuracy_svm_final = accuracy_svm_final + accuracy_score(y_svm, y_test)\n",
    "    accuracy_rf_final = accuracy_rf_final + accuracy_score(y_rf, y_test)\n",
    "print('%%%%%%%%FINAL RESULTS%%%%%%%%%%%%%')\n",
    "print('Average Accuracy of SVM (All Folds): ', accuracy_svm_final/5)\n",
    "print('Average Accuracy of RF (All Folds): ', accuracy_rf_final/5)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
