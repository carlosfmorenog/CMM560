{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfmorenog/CMM560/blob/main/CMM560_Topic_8/CMM560_T8_Lec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OByCteUyuV1O"
      },
      "source": [
        "# Topic 8 - Metrics for Performance Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYIJKLzhuV1R"
      },
      "source": [
        "## Aims of the Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvlF-TtCuV1R"
      },
      "source": [
        "* Learn different metrics used to evaluate classification frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLorA4HzuV1R"
      },
      "source": [
        "* Understand some alternatives to design proper tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t15x6Y-yuV1S"
      },
      "source": [
        "## Resources for the Lecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VR6dM1JuV1S"
      },
      "source": [
        "### Websites\n",
        "\n",
        "* https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
        "* https://en.wikipedia.org/wiki/Precision_and_recall\n",
        "* https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
        "* https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "* https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
        "* https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2\n",
        "* https://machinelearningmastery.com/k-fold-cross-validation/\n",
        "* https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
        "* https://medium.com/mlearning-ai/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nINGGOsuV1T"
      },
      "source": [
        "### Online Courses\n",
        "\n",
        "* [Deep Learning Specialization by Andrew NG (Coursera)](https://es.coursera.org/specializations/deep-learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8SS6fNruV1T"
      },
      "source": [
        "## Some important concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2yonRpnuV1T"
      },
      "source": [
        "![Fig. 1. Typical Data Split](https://www.dropbox.com/s/oze1q3wj7d71pa1/traintestvalid.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A-0D8aKuV1U"
      },
      "source": [
        "* `Generalisation`: The ability to correctly classify new examples different from those used for training a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IlgEA0euV1U"
      },
      "source": [
        "![Fig. 2. Sample data of a binary dataset](https://www.dropbox.com/s/iiorih73voblfb9/data.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlnjcKIsuV1U"
      },
      "source": [
        "* `Overfitting`: The trained classifier gets a $100\\%$ accuracy in the training/validation data, but only $50\\%$ in the testing data.\n",
        "    * Also known as `high variance`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceN1FkPkuV1U"
      },
      "source": [
        "![Fig. 2a. Sample data of a binary dataset with an overfitted model](https://www.dropbox.com/s/gtyc6o096si85ii/overfitting.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgUkrXDSuV1V"
      },
      "source": [
        "* `Underfitting`: The learned classifier is so simplistic that does not capture the structure of the data.\n",
        "    * This translates on a poor performance on the  validation data\n",
        "    * Also known as `high bias`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZpPnhnguV1V"
      },
      "source": [
        "![Fig. 2b. Sample data of a binary dataset with an underfitted model](https://www.dropbox.com/s/sc6t7pocg90xrak/underfitting.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFto1ji6uV1V"
      },
      "source": [
        "* What do we expect?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcfKNFHQuV1V"
      },
      "source": [
        "![Fig. 2c. Sample data of a binary dataset with \"just right\" classification](https://www.dropbox.com/s/8qmcr98jeghw7fe/justright.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-W6_vwquV1V"
      },
      "source": [
        "### The bias-variance trade-off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZuxEeP8uV1W"
      },
      "source": [
        "* As you can see, a model can either have high bias or high variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h346bY4euV1W"
      },
      "source": [
        "* The main objective of machine learning is to find a function $h(x)$ that maps feature $X$ to class/target $y$ minimising:\n",
        "    * bias error\n",
        "    * variance error\n",
        "    * irreducible error (noise in the data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHwCWr02uV1X"
      },
      "source": [
        "Typically[$^1$](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229), the **Error** of a learner/classifier is modelled using the following equation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13PhHDQuV1X"
      },
      "source": [
        "$Err(x)=Bias^2+Variance+Irreducible\\:Error$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXSJ7nRMuV1X"
      },
      "source": [
        "**Why $Bias^2$?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKcnH-SguV1X"
      },
      "source": [
        "## Performance Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7y8C16juV1X"
      },
      "source": [
        "* Assume that we are evaluating the classification success of a **binary** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz4y2cTouV1X"
      },
      "source": [
        "* `True Positives` (TP): This is what many people understand as *accuracy* (but is not!)\n",
        "    * Samples from the *positive class* that are classified correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv44_KVpuV1X"
      },
      "source": [
        "* `True Negatives` (TN): How many samples from the negative class are **NOT** classified as being from the positive one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzpykhpnuV1X"
      },
      "source": [
        "* `False Positives` (FP): How many samples from the negative class are classified as being from the positive class\n",
        "    * Also known in statistics as **False alarms** or **Type I Error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRH7SabCuV1X"
      },
      "source": [
        "* `False Negatives` (FN): How many samples from the positive class are classified as being from the negative class\n",
        "    * Also known in statistics as **Type II Error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkBlzzkuV1X"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNxuaTH2uV1X"
      },
      "source": [
        "* $Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5nHnJqFuV1Y"
      },
      "source": [
        "* The value of the accuracy must be **between $0$ and $1$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwFc0WEuV1Y"
      },
      "source": [
        "* Recall that we said that this is **not** a good measure for imbalanced datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIir7J_0uV1Y"
      },
      "source": [
        "* **WHY?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22dGxf59uV1Z"
      },
      "source": [
        "### Error Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0wsKL6puV1Z"
      },
      "source": [
        "* $Error\\:Rate = \\frac{FP+FN}{TP+TN+FP+FN} = 1 - Accuracy$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ5kz_OuuV1Z"
      },
      "source": [
        "* Also must be **between $0$ and $1$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CMXOPwTuV1a"
      },
      "source": [
        "* **Do you think this one is good for imbalanced datasets?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJl2Ya4suV1a"
      },
      "source": [
        "### Precision and Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__eGQ_VmuV1b"
      },
      "source": [
        "* Assume that we have the following **binary** classification scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-to7GFguV1b"
      },
      "source": [
        "![Fig. 3. Binary Classification Scenario Example](https://www.dropbox.com/s/kojs26i99ksxwuj/Precisionrecall.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-wvfNl9uV1b"
      },
      "source": [
        "#### Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bzYiZwPuV1b"
      },
      "source": [
        "* $Precision = \\frac{TP}{TP+FP}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bODOZHoeuV1b"
      },
      "source": [
        "![Fig. 3a. Precision Illustrated in the Binary Classification Scenario Example](https://www.dropbox.com/s/1y2z9grr3tle83n/Precision.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkGdmuxduV1b"
      },
      "source": [
        "* How much of what I **have** I **need**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4puRlHKuV1c"
      },
      "source": [
        "#### Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVl6ilmGuV1c"
      },
      "source": [
        "* $Recall = \\frac{TP}{TP+FN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjkjFXgeuV1c"
      },
      "source": [
        "![Fig. 3b. Recall illustrated in the binary Classification scenario example](https://www.dropbox.com/s/hpm2rck19vxgnqy/Recall.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1tUnDk9uV1c"
      },
      "source": [
        "* How much of what I **need** I **have**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGwZl3R0uV1c"
      },
      "source": [
        "* The difference is in what you divide the `TP` with"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZPlb7AzuV1c"
      },
      "source": [
        "* Most systems are known to have a precision/recall trade-off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOGrFGr8uV1d"
      },
      "source": [
        "* **Which is better?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trhiBJa3uV1d"
      },
      "source": [
        "#### F1-score (or F1-measure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47YYqhepuV1d"
      },
      "source": [
        "* Harmonic mean between precision and recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT3-DLzKuV1d"
      },
      "source": [
        "* $F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} = \\frac{2 \\times TP}{(2 \\times TP) + FP + FN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xfjlaT3uV1d"
      },
      "source": [
        "### Sensitivity and Specificity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zI0cqE_uV1d"
      },
      "source": [
        "* Similar to precision and recall, but used more in the health sciences domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hijn3a-KuV1d"
      },
      "source": [
        "#### Sensitivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pE-PAhfuV1d"
      },
      "source": [
        "* Just another name for **recall**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9NyBjzcuV1d"
      },
      "source": [
        "![Fig. 3c. Sensitivity illustrated in the binary classification scenario example](https://www.dropbox.com/s/5anc9xoualeij76/sensitivity.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sueLNi5iuV1d"
      },
      "source": [
        "#### Specificity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aLXdNqnuV1d"
      },
      "source": [
        "* The precision for the negative class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG3nMu_nuV1e"
      },
      "source": [
        "![Fig. 3d. Specificity illustrated in the binary classification scenario example](https://www.dropbox.com/s/o3w055swet69c9k/specificity.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJcovm-NuV1e"
      },
      "source": [
        "**Is there any \"F-measure\" for these two?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9LRjT3uV1e"
      },
      "source": [
        "### The Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__3gqh-juV1e"
      },
      "source": [
        "* Also known as *error matrix*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3X6mdNuV1e"
      },
      "source": [
        "* Table that allows you to visualise the performance of a supervised learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b767poA4uV1e"
      },
      "source": [
        "#### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXpeAKQuV1e"
      },
      "source": [
        "* A classifier has been trained to distinguish cats from dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IR9ykasuV1e"
      },
      "source": [
        "* Assuming a sample of 13 animals (8 cats and 5 dogs), you get the following confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlNU7ZcUuV1e"
      },
      "source": [
        "![Fig 4. Confusion matrix example](https://www.dropbox.com/s/ii6nitc5fxpgb8d/confmat.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn0q-EXpuV1f"
      },
      "source": [
        "* This table can also be interpreted with respect to the previously seen terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiMJl3cjuV1f"
      },
      "source": [
        "![Fig 4a. Confusion matrix with previously seen terms](https://www.dropbox.com/s/dwkpg1epk46b5cm/confmat2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA7Ke0VmuV1f"
      },
      "source": [
        "### Area under the Receiving Operating Characteristic (ROC) Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79zscRi2uV1f"
      },
      "source": [
        "* Suitable to compare classification rates in a more visual way and at **different threshold settings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6RKAoo4uV1f"
      },
      "source": [
        "In reality, **all** classifiers are probabilistic, which means that they don't really tell you if the data point to be classified is class 0 or class 1, but rather they tell you the probability of being class 0 or class 1 (both probabilities add to 100%). Therefore, what the ROC curve plots is the FPR vs TPR when the threshold varies from t=0 to t=1. Usually the threshold is set to t=0.5, but if we vary it we will find different results which are plotted and create the curve. If the threshold is t=0, it means that samples are equally likely to be of class 0 or class 1, and thus both TPR and FPR are 0. If the threshold is t=1, then no samples are classified, which means that TPR and FPR are 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXg-ZRp_uV1f"
      },
      "source": [
        "* It is a probability curve that tells you how much your model is able to distinguish between classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptBSWw7ouV1f"
      },
      "source": [
        "* Higher the AUC, better the model is capable of performing the distinction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS6Nwi6cuV1f"
      },
      "source": [
        "* The curve plots **False Positive Rate** (x-axis) vs **True Positive Rate** (y-axis)\n",
        "    * $FPR: 1-Specificity$\n",
        "    * $TPR: Recall\\:(also\\:known\\:as\\:Sensitivity)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J712UMZuV1g"
      },
      "source": [
        "![Fig. 6. Example of ROC AUC](https://www.dropbox.com/s/orarrocrue4lvzs/ROCAUC.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw6kAfhauV1g"
      },
      "source": [
        "### Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elw0sqYUuV1g"
      },
      "source": [
        "* It's not a bad idea to report this, particularly in large image datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQb5wpgkuV1g"
      },
      "source": [
        "* Not very \"accepted\" in the academic world, but extremely useful in the industrial one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfXJuCRzuV1g"
      },
      "source": [
        "* You can import the `time` module in Python and use the `perf_counter()` function to calculate the time of processes running\n",
        "    * Just be very careful where in your code you calculate the time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IRKdo97uV1g",
        "outputId": "98d16a06-c135-4684-dc70-e16acf2fbfb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed time:  0.00035020000007079943\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "t = time.perf_counter()\n",
        "# do stuff\n",
        "x=0\n",
        "for i in range(1000):\n",
        "    x=x+i\n",
        "# stuff has finished\n",
        "print('Elapsed time: ',time.perf_counter() - t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCkZs0m_uV1h"
      },
      "source": [
        "## What about multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99lufrjuV1h"
      },
      "source": [
        "* So far, we have only spoken of metrics in the context of binary datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpKvKvVLuV1i"
      },
      "source": [
        "* However, in most cases you will deal with multi-class datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbg_dyi8uV1i"
      },
      "source": [
        "* There are many ways to adapt the aforementioned metrics to these scenarios, the most common one being the **One vs All** approach\n",
        "    * Comparing a metric of one class against the rest as if these were a single class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTsLNRzauV1i"
      },
      "source": [
        "* Considering that you can still calculate precision, recall and F1-score for each class (against the rest), another commonly used approach is **macro/weighted/micro** metrics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_0-LdjeuV1i"
      },
      "source": [
        "* `Macro` is the arithmetic mean of all metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsAd6j8MuV1i"
      },
      "source": [
        "* `Weighted` is when we multiply each metric by the number of samples of each class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE3Pr30fuV1j"
      },
      "source": [
        "* `Micro` is the harmonic mean of all metrics, which derives in the system's accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1egLjpyQuV1j"
      },
      "source": [
        "* To see an example of this, I recommend you to visit [this site](https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLpABvkOuV1j"
      },
      "source": [
        "## Validation Frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXUBN4d7uV1j"
      },
      "source": [
        "![Fig. 7. Typical Data Split](https://www.dropbox.com/s/oze1q3wj7d71pa1/traintestvalid.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nGuS7QquV1j"
      },
      "source": [
        "* Technically this is not the only way to split the data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1LxgY9OuV1k"
      },
      "source": [
        "* Even when you split uniformly using train/val/test approach, you are still not considering that maybe some train/val data is better/worse for testing and vice versa!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4DtnsXPuV1k"
      },
      "source": [
        "* To address this issue, there are some iterative validation frameworks which let you split data in different ways and perform multiple tests of the same model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGcvyvN4uV1k"
      },
      "source": [
        "### Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is_Nk47uuV1k"
      },
      "source": [
        "* Simple to understand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AZE8k0CuV1k"
      },
      "source": [
        "* Reduces \"bias\"\n",
        "    * i.e. over-optimistic results that may be caused due to chance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e37FOjIJuV1k"
      },
      "source": [
        "* Based on a single parameter $k$ which defined the number of times that the dataset will be *folded*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcwUF_8uV1k"
      },
      "source": [
        "#### How it works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKGJGG7duV1k"
      },
      "source": [
        "1) Shuffle the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKK-VXr2uV1l"
      },
      "source": [
        "2) Split the dataset into $k$ groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulp31pZpuV1l"
      },
      "source": [
        "3) For each group\n",
        "    * Take that group as the test data\n",
        "    * Take the remaining groups as the training data\n",
        "    * Fit the model\n",
        "    * Retain the score and discard the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnRRTrIfuV1l"
      },
      "source": [
        "4) Once you are done, average/summarise all results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IOetVkzuV1l"
      },
      "source": [
        "#### Which $k$ to choose?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXqu2c7puV1l"
      },
      "source": [
        "* Representative for the model: Large enough to be statistically significant!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKE7_z5LuV1l"
      },
      "source": [
        "* $k=5$ and $k=10$ are the usual standard, but it depends on how many samples you have!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CUdan_MuV1l"
      },
      "source": [
        "* If you do $k=n$ ($n$ being the number of samples in the dataset) then you will test every sample as the test against the rest as the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E80Tt_3suV1l"
      },
      "source": [
        "* This is also known as the **Leave-One-Out** approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKa3dRWIuV1l"
      },
      "source": [
        "* Some datasets (like the one you will use in the bonus part of the lab) already are partitioned in the $k$ folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_YNt-wuV1l"
      },
      "source": [
        "## Metrics used in Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "navgy-5fuV1m"
      },
      "source": [
        "### IoU (A.K.A. Jaccard Index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eviJzgq2uV1m"
      },
      "source": [
        "![Fig 8. Intersection over Union](https://www.dropbox.com/scl/fi/ass5opbcb3lmohtr22a7v/iou.png?rlkey=gj5g79mz05j3rsnoenwu3btc1&raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBBO08qiuV1m"
      },
      "source": [
        "![Fig 9. Intersection over Union Formula](https://www.dropbox.com/scl/fi/tvu4tpdq7w1mns9uukcse/iouformula.png?rlkey=1n20rpcxk9hy2univxqetn1ca&raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAjgbUMTuV1m"
      },
      "source": [
        "* Normally, $IoU \\geq 0.5$ is considered good, while $1$ is perfect!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvHGcvGzuV1m"
      },
      "source": [
        "![Fig 10. Intersection over Union Examples](https://www.dropbox.com/scl/fi/kol5jba0azx6qmrbg2ono/iouexamples.png?rlkey=g8lanp2tu1oqa5sgiyx61y55e&raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g-zhXKbuV1m"
      },
      "source": [
        "### Dice Coefficient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodMAJZKuV1n"
      },
      "source": [
        "* The \"F1-Score\" of computer vision metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrMiwNB6uV1n"
      },
      "source": [
        "* More widely used for segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2-zo3SIuV1n"
      },
      "source": [
        "![Fig 11. Dice Coefficient](https://www.dropbox.com/scl/fi/40ne3x72458zpwp9c6fif/dice.png?rlkey=11aaqn1q1wn49tpp6oqs1oywd&raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZZhQPLuuV1n"
      },
      "source": [
        "**What is the difference between IoU and Dice?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYMXn1i5uV1n"
      },
      "source": [
        "* IoU is more like recall, so it is good to use when you want to detect if a larger amount of the object pixels are outside the area of interest, but also if the detection is **overestimating** where the object is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bc398d3uV1n"
      },
      "source": [
        "* Dice coefficient penalises false positives, which is better for high imbalanced datasets or when the segmentations are not correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmWEu64wuV1o"
      },
      "source": [
        "# LAB: PERFORMANCE MEASURES FOR BINARY DATASETS"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "rise": {
      "backimage": "../mybackimage.png",
      "enable_chalkboard": true,
      "scroll": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}